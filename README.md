# Awesome talking-head

Welcome to the Awesome List for Talking Head Generation! This curated collection of resources focuses on the intriguing domain of 'Talking Head Generation' - an area of computer graphics and artificial intelligence that strives to create lifelike digital recreations of human heads and faces. These 'talking heads' can be used in a variety of applications, from realistic video content and virtual reality, to advanced communication tools and beyond. This list aims to gather key research papers, state-of-the-art algorithms, seminal GitHub repositories, educational videos, inspiring blogs, and more. Whether you are an AI researcher, computer graphics professional, or an AI enthusiast, this list is your one-stop destination to dive into the world of Talking Head Generation. Happy exploring!

## Table of Contents

- [GitHub projects](#github-projects)
- [Google Scholar papers](#google-scholar-papers)

## GitHub projects

- ğŸ”¥ 8985 - [AudioGPT](https://github.com/AIGC-Audio/AudioGPT) - AudioGPT is about understanding and generating speech, music, sound, and talking head. It's a versatile project that combines audio and visuals.
- ğŸ”¥ 5656 - [SadTalker](https://github.com/OpenTalker/SadTalker) - CVPR 2023 contribution for learning realistic 3D motion coefficients for stylized audio-driven single image talking face animation.
- ğŸ”¥ 1902 - [Talking Head Anime Demo](https://github.com/pkhungurn/talking-head-anime-demo) - A demo for creating "Talking Head Anime from a Single Image".
- ğŸ”¥ 1133 - [VideoReTalking](https://github.com/OpenTalker/video-retalking) - SIGGRAPH Asia 2022 project that focuses on audio-based lip synchronization for talking head video editing in the wild.
- ğŸ”¥ 1026 - [Talking Head Anime 2 Demo](https://github.com/pkhungurn/talking-head-anime-2-demo) - Demo programs for the more expressive "Talking Head Anime from a Single Image 2" project.
- ğŸ”¥ 905 - [GeneFace](https://github.com/yerfor/GeneFace) - ICLR 2023 project, GeneFace, which deals with generalized and high-fidelity 3D talking face synthesis.
- ğŸ”¥ 886 - [Live Speech Portraits](https://github.com/YuanxunLu/LiveSpeechPortraits) - SIGGRAPH Asia 2021 project for creating real-time photorealistic talking-head animations called "Live Speech Portraits".
- ğŸ”¥ 796 - [Realistic-Neural-Talking-Head-Models](https://github.com/vincent-thevenin/Realistic-Neural-Talking-Head-Models) - An implementation of Few-Shot Adversarial Learning of Realistic Neural Talking Head Models by Egor Zakharov et al.
- ğŸ”¥ 778 - [Depth-Aware Generative Adversarial Network](https://github.com/harlanhong/CVPR2022-DaGAN) - Official code for CVPR2022 paper on  talking head video generation using Depth-Aware Generative Adversarial Network.
- ğŸ”¥ 744 - [AD-NeRF](https://github.com/YudongGuo/AD-NeRF) - A PyTorch implementation of "AD-NeRF: Audio Driven Neural Radiance Fields for Talking Head Synthesis".
- ğŸ”¥ 669 - [Talking Head Anime 3 Demo](https://github.com/pkhungurn/talking-head-anime-3-demo) - Demo programs for the project "Talking Head(?) Anime from a Single Image 3: Now the Body Too".
- ğŸ”¥ 603 - [Audio-driven-TalkingFace-HeadPose](https://github.com/yiranran/Audio-driven-TalkingFace-HeadPose) - Code for "Audio-driven Talking Face Video Generation with Learning-based Personalized Head Pose".
- ğŸ”¥ 590 - [Talking Heads](https://github.com/grey-eye/talking-heads) - Another implementation of "Few-Shot Adversarial Learning of Realistic Neural Talking Head Models" by Egor Zakharov et al.
- ğŸ”¥ 559 - [One-Shot Free-View Neural Talking-Head Synthesis](https://github.com/zhanglonghao1992/One-Shot_Free-View_Neural_Talking_Head_Synthesis) - Pytorch implementation for "One-Shot Free-View Neural Talking-Head Synthesis for Video Conferencing".
- ğŸ”¥ 343 - [MetaPortrait](https://github.com/Meta-Portrait/MetaPortrait) - CVPR 2023 project, MetaPortrait, that aims at identity-preserving talking head generation with fast personalized adaptation.
- ğŸ”¥ 339 - [Text2Video](https://github.com/sibozhang/Text2Video) - ICASSP 2022 project titled "Text2Video: text-driven talking-head video synthesis with phonetic dictionary".
- ğŸ”¥ 254 - [Learning Dynamic Facial Radiance Fields](https://github.com/sstzal/DFRF) - ECCV2022 implementation for "Learning Dynamic Facial Radiance Fields for Few-Shot Talking Head Synthesis".
- ğŸ”¥ 253 - [Diffused Heads](https://github.com/MStypulkowski/diffused-heads) - Official repository for "Diffused Heads: Diffusion Models Beat GANs on Talking-Face Generation".
- ğŸ”¥ 193 - [Audio2Head](https://github.com/wangsuzhen/Audio2Head) - Conference of IJCAI 2021 paper for "Audio2Head: Audio-driven One-shot Talking-head Generation with Natural Head Motion".
- ğŸŒŸ187 - [Talking-head-Generation-with-Rhythmic-Head-Motion](https://github.com/lelechen63/Talking-head-Generation-with-Rhythmic-Head-Motion): A framework to generate talking head videos with rhythmic head motions, adding life-like movements and enhancing realism.
- ğŸŒŸ161 - [Co-Speech-Motion-Generation](https://github.com/TheTempAccount/Co-Speech-Motion-Generation): Freeform body motion generation from speech, with potential applications in virtual characters and animations.
- ğŸŒŸ143 - [Few-Shot-Adversarial-Learning-for-face-swap](https://github.com/shoutOutYangJie/Few-Shot-Adversarial-Learning-for-face-swap): Unofficial re-implementation of the paper "Few-Shot Adversarial Learning of Realistic Neural Talking Head Models," fusing deep learning and computer vision techniques.
- ğŸŒŸ118 - [Write-a-Speaker](https://github.com/FuxiVirtualHuman/Write-a-Speaker): Mocap dataset of â€œWrite-a-speaker: Text-based Emotional and Rhythmic Talking-head Generation,â€ which creates expressive talking heads by leveraging mocap data and text input.
- ğŸŒŸ102 - [face-vid2vid](https://github.com/zhengkw18/face-vid2vid): Unofficial implementation of one-shot free-view neural talking head synthesis, enabling customization for various face poses and lighting conditions.
- ğŸŒŸ83 - [talking-head-generation-survey](https://github.com/lelechen63/talking-head-generation-survey): Official GitHub repo for the paper "What comprises a good talking-head video generation?: A Survey and Benchmark," discussing the essential qualities and state-of-the-art models in talking head generation.
- ğŸŒŸ65 - [ask-fake-ai-karen](https://github.com/ChintanTrivedi/ask-fake-ai-karen): AI-generated talking head videos of fake people responding to user input questions, exploring the interaction possibilities with generated characters.
- ğŸŒŸ11 - [fivem-tgiann-look-talking-player](https://github.com/TGIANN/fivem-tgiann-look-talking-player): A small game addition where the character turns the head towards the talking player, increasing immersion.
- ğŸŒŸ5 - [TalkingHead](https://github.com/pulcher/TalkingHead): A creepy talking head with eyes, demonstrating creative applications in talking head generation.

## Google Scholar papers

- :star: [Text-based editing of talking-head video](https://dl.acm.org/doi/abs/10.1145/3306346.3323028) (206 citations) - Proposes a novel method to edit talking-head videos to change speech content or remove filler words, making it challenging for viewers to distinguish between the original and the edited content.
- :trophy: [Few-shot adversarial learning of realistic neural talking head models](http://openaccess.thecvf.com/content_ICCV_2019/html/Zakharov_Few-Shot_Adversarial_Learning_of_Realistic_Neural_Talking_Head_Models_ICCV_2019_paper.html) (573 citations) - Develops a photorealistic talking-head model that can create realistic and personalized talking head sequences, even for portrait paintings.
- :tada: [Talking-head generation with rhythmic head motion](https://link.springer.com/chapter/10.1007/978-3-030-58545-7_3) (104 citations) - Introduces a neural approach for talking-head video generation which considers the rhythmic head motion aligned with the audio input.
- :sparkles: [Mixed feelings: expression of non-basic emotions in a muscle-based talking head](https://link.springer.com/article/10.1007/s10055-005-0153-5) (141 citations) - Presents a muscle-based talking-head system capable of expressing a continuum of non-basic emotions through an anatomically accurate model.
- :rocket: [One-shot free-view neural talking-head synthesis for video conferencing](http://openaccess.thecvf.com/content/CVPR2021/html/Wang_One-Shot_Free-View_Neural_Talking-Head_Synthesis_for_Video_Conferencing_CVPR_2021_paper.html) (203 citations) - Proposes a neural talking-head video synthesis model that learns to synthesize a talking-head video using a source image and is applicable to video conferencing.
- :musical_note: [Makelttalk: speaker-aware talking-head animation](https://dl.acm.org/doi/abs/10.1145/3414685.3417774) (208 citations) - Generates expressive talking-head videos from a single facial image, considering both facial expressions and talking-head dynamics.
- :tv: [Photo-real talking head with deep bidirectional LSTM](https://ieeexplore.ieee.org/abstract/document/7178899/) (133 citations) - Presents a deep bidirectional LSTM model for generating video-realistic talking-head animations to attract users' attention in human-machine interaction.
- :loud_sound: [Ad-nerf: Audio driven neural radiance fields for talking head synthesis](http://openaccess.thecvf.com/content/ICCV2021/html/Guo_AD-NeRF_Audio_Driven_Neural_Radiance_Fields_for_Talking_Head_Synthesis_ICCV_2021_paper.html) (141 citations) - Introduces an audio-driven talking head synthesis method using neural radiance fields to generate natural talking-head sequences.
- :movie_camera: [Expressive talking head generation with granular audio-visual control](http://openaccess.thecvf.com/content/CVPR2022/html/Liang_Expressive_Talking_Head_Generation_With_Granular_Audio-Visual_Control_CVPR_2022_paper.html) (46 citations) - Allows for granular audio-visual control to generate expressive talking head animations that consider both lip synchronization and emotional expression.
- :headphones: [Audio2head: Audio-driven one-shot talking-head generation with natural head motion](https://arxiv.org/abs/2107.09293) (59 citations) - Proposes a method for one-shot talking-head generation that uses audio-driven techniques and estimates holistic head movements for photo-realistic talking-head videos.
- ğŸ“š [Write-a-speaker: Text-based emotional and rhythmic talking-head generation](https://ojs.aaai.org/index.php/AAAI/article/view/16286) (38 citations)\
A novel text-based talking-head video generation framework that creates high-quality photorealistic talking-head videos with various facial expressions.
- ğŸ“š [Learned spatial representations for few-shot talking-head synthesis](http://openaccess.thecvf.com/content/ICCV2021/html/Meshry_Learned_Spatial_Representations_for_Few-Shot_Talking-Head_Synthesis_ICCV_2021_paper.html) (19 citations)\
A two-step framework that synthesizes talking heads by decomposing the process into spatial and style components.
- ğŸ“š [DFA-NeRF: Personalized talking head generation via disentangled face attributes neural rendering](https://arxiv.org/abs/2201.00791) (32 citations)\
A comparison of different aspects of talking head generation works, focusing on methods for specific targets or arbitrary images and the use of audio features.
- ğŸ“š [Training a talking head](https://ieeexplore.ieee.org/abstract/document/1167046/) (57 citations)\
Describes the creation of a talking head using Cyberware laser scan data and Optotrak LED markers.
- ğŸ“š [Free-headgan: Neural talking head synthesis with explicit gaze control](https://ieeexplore.ieee.org/abstract/document/10061572/) (4 citations)\
Talking head synthesis using an image-to-image translation network, based on the generator of HeadGAN, without AdaIN layers.
- ğŸ“š [Txt2vid: Ultra-low bitrate compression of talking-head videos via text](https://ieeexplore.ieee.org/abstract/document/9953071/) (10 citations)\
A novel compression pipeline for audio-video talking-head videos, converting them to text using a state-of-the-art voice cloning model.
- ğŸ“š [One-Shot High-Fidelity Talking-Head Synthesis with Deformable Neural Radiance Field](http://openaccess.thecvf.com/content/CVPR2023/html/Li_One-Shot_High-Fidelity_Talking-Head_Synthesis_With_Deformable_Neural_Radiance_Field_CVPR_2023_paper.html) (1 citation)\
A high-fidelity and deformable NeRF (HiDe-NeRF) approach for one-shot talking head synthesis, improving synthesis fidelity.
- ğŸ“š [Styletalk: One-shot talking head generation with controllable speaking styles](https://arxiv.org/abs/2301.01081) (5 citations)\
A talking head generation system capable of generating videos with diverse speaking styles, evaluated for quality.
- ğŸ“š [Difftalk: Crafting diffusion models for generalized talking head synthesis](https://arxiv.org/abs/2301.03786) (8 citations)\
A crafted conditional Diffusion model for generalized Talking head synthesis (DiffTalk), capable of synthesizing high-fidelity and expressive talking heads.
- ğŸ“š [Talking Head from Speech Audio using a Pre-trained Image Generator](https://dl.acm.org/doi/abs/10.1145/3503161.3548101) (3 citations)\
An approach that generates talking-head videos with accurate mouth movements conditioned on speech audio, improving visual quality.
- ğŸŸ¢ [Generative adversarial talking head: Bringing portraits to life with a weakly supervised neural network](https://arxiv.org/abs/1803.07716) (36 citations) \
This paper introduces Generative Adversarial Talking Head (GATH), a novel deep generative neural network for fully automatic facial expression synthesis from an arbitrary portrait.
- ğŸŸ¢ [High quality lip-sync animation for 3D photo-realistic talking head](https://ieeexplore.ieee.org/abstract/document/6288925/) (41 citations) \
This research extends prior high-quality 2D photo-realistic talking head work to create a 3D talking head with high-quality lip-sync animation.
- ğŸŸ¢ [3d-talkemo: Learning to synthesize 3D emotional talking head](https://arxiv.org/abs/2104.12051) (9 citations) \
This paper presents a deep neural network that generates 3D talking head animation with various emotions, a challenge still unsolved in facial animation.
- ğŸŸ¢ [Memory-Augmented Contrastive Learning for Talking Head Generation](https://ieeexplore.ieee.org/abstract/document/10096593/) (2 citations) \
This research focuses on talking head generation, with the goal to synthesize a realistic-looking talking head video from one reference facial image and a piece of speech.
- ğŸŸ¢ [Audio-driven Talking Head Generation with Transformer and 3D Morphable Model](https://dl.acm.org/doi/abs/10.1145/3503161.3551574) (4 citations) \
This paper presents a method for talking head video generation conditioned on the identity and audio signals of a speaker, using a combination of transformers and 3D morphable models.
- ğŸŸ¢ [An expressive text-driven 3d talking head](https://dl.acm.org/doi/abs/10.1145/2503385.2503473) (17 citations) \
This research works on creating an expressive 3D talking head by leveraging a large dataset, with the first step being constructing a 2D talking head using Active Appearance Models.
- ğŸŸ¢ [Talking head generation with audio and speech related facial action units](https://arxiv.org/abs/2110.09951) (9 citations) \
This paper explores how to generate a talking head video by inputting a person's image and audio, and identifying the relevant facial action units to match the speech.
- ğŸŸ¢ [StyleTalker: One-shot Style-based Audio-driven Talking Head Video Generation](https://arxiv.org/abs/2208.10922) (5 citations) \
StyleTalker is a talking head video generation system that is able to synthesize talking head videos with impressive results, using latent codes to reflect the speech styles.
- ğŸŸ¢ [AnyoneNet: Synchronized Speech and Talking Head Generation for Arbitrary Persons](https://ieeexplore.ieee.org/abstract/document/9917325/) (5 citations) \
AnyoneNet generates text-driven talking-head videos using a single face image of an arbitrary person as input, creating synchronized lip movements in the talking head.
- ğŸŸ¢ [An audiovisual talking head for augmented speech generation: models and animations based on a real speaker's articulatory data](https://link.springer.com/chapter/10.1007/978-3-540-70517-8_14) (74 citations) \
This research aims to control a talking head with real speaker's articulatory data, enabling more accurate and natural animation.
- ğŸŸ¢ [Progressive Disentangled Representation Learning for Fine-Grained Controllable Talking Head Synthesis](http://openaccess.thecvf.com/content/CVPR2023/html/Wang_Progressive_Disentangled_Representation_Learning_for_Fine-Grained_Controllable_Talking_Head_Synthesis_CVPR_2023_paper.html) (1 citation) \
This paper presents a novel one-shot talking head synthesis method that achieves disentangled and fine-grained control over lip motion, eye gaze & blink, head pose, and emotional expression.
- ğŸŸ¢ [Videoretalking: Audio-based lip synchronization for talking head video editing in the wild](https://dl.acm.org/doi/abs/10.1145/3550469.3555399) (3 citations) \
VideoReTalking is a new system that edits the faces of real-world talking head videos based on modified expressions, focusing on lip synchronization according to the input audio.

---

This initial version of the Awesome List was generated with the help of the [Awesome List Generator](https://github.com/alialsaeedi19/GPT-Awesome-List-Maker). It's an open-source Python package that uses the power of GPT models to automatically curate and generate starting points for resource lists related to a specific topic. 